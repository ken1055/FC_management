# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œå…¨ã‚¬ã‚¤ãƒ‰

## ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³

### **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹æˆ**

- **SQLite**: ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ï¼ˆ`agency.db`ï¼‰
- **Supabase**: æœ¬ç•ªç’°å¢ƒç”¨ï¼ˆPostgreSQLï¼‰

### **ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã¨ä»¶æ•°**

| ãƒ†ãƒ¼ãƒ–ãƒ«å           | ä»¶æ•° | èª¬æ˜                 |
| -------------------- | ---- | -------------------- |
| stores               | 1    | FC åº—èˆ—æƒ…å ±          |
| customers            | 0    | é¡§å®¢æƒ…å ±             |
| sales                | 2    | å£²ä¸Šãƒ‡ãƒ¼ã‚¿           |
| users                | 1    | åº—èˆ—ãƒ¦ãƒ¼ã‚¶ãƒ¼         |
| admins               | 1    | ç®¡ç†è€…               |
| groups               | -    | ã‚°ãƒ«ãƒ¼ãƒ—ç®¡ç†         |
| royalty_calculations | -    | ãƒ­ã‚¤ãƒ¤ãƒªãƒ†ã‚£è¨ˆç®—çµæœ |
| royalty_settings     | -    | ãƒ­ã‚¤ãƒ¤ãƒªãƒ†ã‚£è¨­å®š     |

## ğŸ”§ æ–¹æ³• 1: SQLite ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

### **1.1 å®Œå…¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆæ¨å¥¨ï¼‰**

```bash
# 1. ã‚¹ã‚­ãƒ¼ãƒã¨ãƒ‡ãƒ¼ã‚¿ã‚’åŒæ™‚ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
sqlite3 /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db .dump > fc_database_backup.sql

# 2. åœ§ç¸®ã—ã¦ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
gzip fc_database_backup.sql
```

### **1.2 ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**

```bash
# ã‚¹ã‚­ãƒ¼ãƒã®ã¿
sqlite3 /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db .schema > schema_only.sql

# å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿
sqlite3 /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM stores;" > stores_data.csv
sqlite3 /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM sales;" > sales_data.csv
sqlite3 /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM users;" > users_data.csv
sqlite3 /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM admins;" > admins_data.csv
```

### **1.3 CSV å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**

```bash
# ãƒ˜ãƒƒãƒ€ãƒ¼ä»˜ãCSV
sqlite3 -header -csv /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM stores;" > stores.csv
sqlite3 -header -csv /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM sales;" > sales.csv
sqlite3 -header -csv /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM users;" > users.csv
sqlite3 -header -csv /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM admins;" > admins.csv
```

### **1.4 JSON å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**

```bash
# Node.jsã‚¹ã‚¯ãƒªãƒ—ãƒˆã§JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
node -e "
const sqlite3 = require('sqlite3').verbose();
const fs = require('fs');

const db = new sqlite3.Database('./agency.db');
const tables = ['stores', 'customers', 'sales', 'users', 'admins', 'groups', 'royalty_calculations'];
const result = {};

let completed = 0;
tables.forEach(table => {
  db.all(\`SELECT * FROM \${table}\`, [], (err, rows) => {
    if (!err) result[table] = rows;
    completed++;
    if (completed === tables.length) {
      fs.writeFileSync('database_export.json', JSON.stringify(result, null, 2));
      console.log('JSON export completed: database_export.json');
      db.close();
    }
  });
});
"
```

## ğŸŒ æ–¹æ³• 2: Supabase ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

### **2.1 Supabase CLI ä½¿ç”¨**

```bash
# 1. Supabase CLIã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
npm install -g supabase

# 2. ãƒ­ã‚°ã‚¤ãƒ³
supabase login

# 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãƒªãƒ³ã‚¯
supabase link --project-ref YOUR_PROJECT_REF

# 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ€ãƒ³ãƒ—
supabase db dump --data-only > supabase_data.sql
supabase db dump --schema-only > supabase_schema.sql
supabase db dump > supabase_full_backup.sql
```

### **2.2 pg_dump ä½¿ç”¨ï¼ˆç›´æ¥æ¥ç¶šï¼‰**

```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæƒ…å ±ãŒå¿…è¦
pg_dump "postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].supabase.co:5432/postgres" > supabase_backup.sql

# ãƒ‡ãƒ¼ã‚¿ã®ã¿
pg_dump --data-only "postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].supabase.co:5432/postgres" > supabase_data_only.sql

# ã‚¹ã‚­ãƒ¼ãƒã®ã¿
pg_dump --schema-only "postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].supabase.co:5432/postgres" > supabase_schema_only.sql
```

### **2.3 Supabase Dashboard ä½¿ç”¨**

1. **Supabase ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**ã«ãƒ­ã‚°ã‚¤ãƒ³
2. **Settings** â†’ **Database**
3. **Connection pooling** â†’ **Connection string**ã‚’ã‚³ãƒ”ãƒ¼
4. **Table Editor**ã§å„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’**Export as CSV**

## ğŸ”„ æ–¹æ³• 3: MySQL å½¢å¼ã¸ã®å¤‰æ›

### **3.1 è‡ªå‹•å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**

```javascript
// convert_to_mysql.js
const fs = require("fs");

function convertSQLiteToMySQL(sqliteFile, outputFile) {
  let sql = fs.readFileSync(sqliteFile, "utf8");

  // SQLite â†’ MySQLå¤‰æ›
  sql = sql
    // AUTOINCREMENT â†’ AUTO_INCREMENT
    .replace(/AUTOINCREMENT/g, "AUTO_INCREMENT")
    // INTEGER PRIMARY KEY â†’ INT PRIMARY KEY AUTO_INCREMENT
    .replace(
      /INTEGER PRIMARY KEY AUTOINCREMENT/g,
      "INT PRIMARY KEY AUTO_INCREMENT"
    )
    // TEXT â†’ VARCHAR(255) ã¾ãŸã¯ TEXT
    .replace(/(\w+)\s+TEXT(?!\s+(NOT\s+NULL|DEFAULT|UNIQUE))/g, "$1 TEXT")
    // REAL â†’ DECIMAL
    .replace(/REAL/g, "DECIMAL(10,2)")
    // TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    .replace(
      /TIMESTAMP DEFAULT CURRENT_TIMESTAMP/g,
      "TIMESTAMP DEFAULT CURRENT_TIMESTAMP"
    )
    // SQLiteã®æ—¥ä»˜é–¢æ•°ã‚’MySQLã«å¤‰æ›
    .replace(/date\('now'\)/g, "CURDATE()")
    .replace(/datetime\('now'\)/g, "NOW()")
    // UNIQUEåˆ¶ç´„ã®èª¿æ•´
    .replace(/,\s*UNIQUE\s*\(([^)]+)\)/g, ", UNIQUE KEY ($1)")
    // å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®èª¿æ•´
    .replace(/FOREIGN KEY/g, "CONSTRAINT FOREIGN KEY")
    // ã‚¨ãƒ³ã‚¸ãƒ³ã¨charsetã‚’è¿½åŠ 
    .replace(/\);$/gm, ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;");

  fs.writeFileSync(outputFile, sql);
  console.log(`MySQLå¤‰æ›å®Œäº†: ${outputFile}`);
}

// ä½¿ç”¨ä¾‹
convertSQLiteToMySQL("fc_database_backup.sql", "fc_database_mysql.sql");
```

### **3.2 æ‰‹å‹•å¤‰æ›ã®ãƒã‚¤ãƒ³ãƒˆ**

```sql
-- SQLite â†’ MySQLå¤‰æ›ä¾‹

-- 1. ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
-- SQLite
CREATE TABLE stores (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT NOT NULL
);

-- MySQL
CREATE TABLE stores (
  id INT PRIMARY KEY AUTO_INCREMENT,
  name VARCHAR(255) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- 2. ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
-- SQLite â†’ MySQL
-- INTEGER â†’ INT
-- TEXT â†’ VARCHAR(255) ã¾ãŸã¯ TEXT
-- REAL â†’ DECIMAL(10,2)
-- BLOB â†’ LONGBLOB
```

## ğŸ“¦ æ–¹æ³• 4: å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ

### **4.1 ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**

```bash
#!/bin/bash
# backup_database.sh

BACKUP_DIR="./database_backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_NAME="fc_database_${TIMESTAMP}"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p $BACKUP_DIR

echo "=== FCåº—èˆ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹ ==="

# 1. SQLiteãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸­..."
sqlite3 ./agency.db .dump > "$BACKUP_DIR/${BACKUP_NAME}_sqlite.sql"

# 2. ã‚¹ã‚­ãƒ¼ãƒã®ã¿
sqlite3 ./agency.db .schema > "$BACKUP_DIR/${BACKUP_NAME}_schema.sql"

# 3. CSVå½¢å¼
echo "CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­..."
sqlite3 -header -csv ./agency.db "SELECT * FROM stores;" > "$BACKUP_DIR/${BACKUP_NAME}_stores.csv"
sqlite3 -header -csv ./agency.db "SELECT * FROM sales;" > "$BACKUP_DIR/${BACKUP_NAME}_sales.csv"
sqlite3 -header -csv ./agency.db "SELECT * FROM users;" > "$BACKUP_DIR/${BACKUP_NAME}_users.csv"
sqlite3 -header -csv ./agency.db "SELECT * FROM admins;" > "$BACKUP_DIR/${BACKUP_NAME}_admins.csv"

# 4. JSONå½¢å¼
echo "JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­..."
node -e "
const sqlite3 = require('sqlite3').verbose();
const fs = require('fs');

const db = new sqlite3.Database('./agency.db');
const tables = ['stores', 'customers', 'sales', 'users', 'admins', 'groups', 'royalty_calculations', 'royalty_settings'];
const result = {};

let completed = 0;
tables.forEach(table => {
  db.all(\`SELECT * FROM \${table}\`, [], (err, rows) => {
    if (!err) result[table] = rows;
    completed++;
    if (completed === tables.length) {
      fs.writeFileSync('$BACKUP_DIR/${BACKUP_NAME}_data.json', JSON.stringify(result, null, 2));
      db.close();
    }
  });
});
"

# 5. MySQLå½¢å¼å¤‰æ›
echo "MySQLå½¢å¼ã«å¤‰æ›ä¸­..."
node convert_to_mysql.js "$BACKUP_DIR/${BACKUP_NAME}_sqlite.sql" "$BACKUP_DIR/${BACKUP_NAME}_mysql.sql"

# 6. åœ§ç¸®
echo "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’åœ§ç¸®ä¸­..."
cd $BACKUP_DIR
tar -czf "${BACKUP_NAME}_complete.tar.gz" ${BACKUP_NAME}_*
cd ..

echo "=== ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº† ==="
echo "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å ´æ‰€: $BACKUP_DIR"
echo "åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«: ${BACKUP_NAME}_complete.tar.gz"
```

### **4.2 ä½¿ç”¨æ–¹æ³•**

```bash
# å®Ÿè¡Œæ¨©é™ä»˜ä¸
chmod +x backup_database.sh

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
./backup_database.sh
```

## ğŸš€ æ–¹æ³• 5: è‡ªå‹•ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```javascript
// database_export.js - å®Œå…¨è‡ªå‹•ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
const sqlite3 = require("sqlite3").verbose();
const fs = require("fs");
const path = require("path");

class DatabaseExporter {
  constructor(dbPath) {
    this.dbPath = dbPath;
    this.db = new sqlite3.Database(dbPath);
    this.exportDir = "./exports";
    this.timestamp = new Date()
      .toISOString()
      .replace(/[:.]/g, "-")
      .slice(0, 19);
  }

  async init() {
    if (!fs.existsSync(this.exportDir)) {
      fs.mkdirSync(this.exportDir, { recursive: true });
    }
  }

  // ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§å–å¾—
  async getTables() {
    return new Promise((resolve, reject) => {
      this.db.all(
        "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'",
        [],
        (err, rows) => {
          if (err) reject(err);
          else resolve(rows.map((row) => row.name));
        }
      );
    });
  }

  // ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
  async getTableData(tableName) {
    return new Promise((resolve, reject) => {
      this.db.all(`SELECT * FROM ${tableName}`, [], (err, rows) => {
        if (err) reject(err);
        else resolve(rows);
      });
    });
  }

  // JSONå½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
  async exportJSON() {
    const tables = await this.getTables();
    const data = {};

    for (const table of tables) {
      data[table] = await this.getTableData(table);
    }

    const filename = `${this.exportDir}/database_${this.timestamp}.json`;
    fs.writeFileSync(filename, JSON.stringify(data, null, 2));
    console.log(`JSON export completed: ${filename}`);
    return filename;
  }

  // CSVå½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
  async exportCSV() {
    const tables = await this.getTables();
    const files = [];

    for (const table of tables) {
      const data = await this.getTableData(table);
      if (data.length === 0) continue;

      const headers = Object.keys(data[0]);
      const csvContent = [
        headers.join(","),
        ...data.map((row) => headers.map((h) => `"${row[h] || ""}"`).join(",")),
      ].join("\n");

      const filename = `${this.exportDir}/${table}_${this.timestamp}.csv`;
      fs.writeFileSync(filename, csvContent);
      files.push(filename);
    }

    console.log(`CSV export completed: ${files.length} files`);
    return files;
  }

  // SQLå½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
  async exportSQL() {
    const { exec } = require("child_process");
    const filename = `${this.exportDir}/database_${this.timestamp}.sql`;

    return new Promise((resolve, reject) => {
      exec(`sqlite3 ${this.dbPath} .dump > ${filename}`, (error) => {
        if (error) reject(error);
        else {
          console.log(`SQL export completed: ${filename}`);
          resolve(filename);
        }
      });
    });
  }

  // MySQLå½¢å¼å¤‰æ›
  convertToMySQL(sqlFile) {
    const sql = fs.readFileSync(sqlFile, "utf8");
    const mysqlSql = sql
      .replace(/AUTOINCREMENT/g, "AUTO_INCREMENT")
      .replace(
        /INTEGER PRIMARY KEY AUTOINCREMENT/g,
        "INT PRIMARY KEY AUTO_INCREMENT"
      )
      .replace(/TEXT/g, "VARCHAR(255)")
      .replace(/REAL/g, "DECIMAL(10,2)")
      .replace(/\);$/gm, ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;");

    const mysqlFile = sqlFile.replace(".sql", "_mysql.sql");
    fs.writeFileSync(mysqlFile, mysqlSql);
    console.log(`MySQL conversion completed: ${mysqlFile}`);
    return mysqlFile;
  }

  // å®Œå…¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ
  async exportAll() {
    await this.init();
    console.log("=== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Œå…¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé–‹å§‹ ===");

    try {
      const jsonFile = await this.exportJSON();
      const csvFiles = await this.exportCSV();
      const sqlFile = await this.exportSQL();
      const mysqlFile = this.convertToMySQL(sqlFile);

      console.log("=== ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº† ===");
      return {
        json: jsonFile,
        csv: csvFiles,
        sql: sqlFile,
        mysql: mysqlFile,
      };
    } catch (error) {
      console.error("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼:", error);
      throw error;
    } finally {
      this.db.close();
    }
  }
}

// ä½¿ç”¨ä¾‹
if (require.main === module) {
  const exporter = new DatabaseExporter("./agency.db");
  exporter
    .exportAll()
    .then((result) => {
      console.log("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆçµæœ:", result);
    })
    .catch((error) => {
      console.error("ã‚¨ãƒ©ãƒ¼:", error);
    });
}

module.exports = DatabaseExporter;
```

## ğŸ“‹ æ¨å¥¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ‰‹é †

### **Step 1: å³åº§å®Ÿè¡Œå¯èƒ½**

```bash
# æœ€ã‚‚ç°¡å˜ãªæ–¹æ³•
sqlite3 /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db .dump > fc_complete_backup.sql
```

### **Step 2: è©³ç´°ãƒ‡ãƒ¼ã‚¿ç¢ºèª**

```bash
# ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ç¢ºèª
sqlite3 /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT 'stores' as table_name, COUNT(*) as count FROM stores UNION ALL SELECT 'sales', COUNT(*) FROM sales UNION ALL SELECT 'users', COUNT(*) FROM users UNION ALL SELECT 'admins', COUNT(*) FROM admins;"

# å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª
sqlite3 -header -column /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM stores;"
sqlite3 -header -column /Users/hanmayuujirou/Documents/FCç®¡ç†/agency.db "SELECT * FROM sales;"
```

### **Step 3: ç”¨é€”åˆ¥ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**

- **é–‹ç™ºç”¨**: JSON å½¢å¼
- **Excel åˆ†æç”¨**: CSV å½¢å¼
- **ç§»è¡Œç”¨**: SQL å½¢å¼ï¼ˆMySQL å¤‰æ›æ¸ˆã¿ï¼‰
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨**: åœ§ç¸® SQL å½¢å¼

## âš ï¸ æ³¨æ„äº‹é …

1. **ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰æƒ…å ±**: ç®¡ç†è€…ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯ãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚Œã¦ã„ã¾ã™
2. **ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¯ç›¸å¯¾ãƒ‘ã‚¹ã§ã™
3. **å¤–éƒ¨ã‚­ãƒ¼**: SQLite â†’ MySQL ç§»è¡Œæ™‚ã¯å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®èª¿æ•´ãŒå¿…è¦
4. **æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°**: UTF-8 ã§çµ±ä¸€ã•ã‚Œã¦ã„ã¾ã™

**ã©ã®æ–¹æ³•ã‚’è©¦ã—ãŸã„ã‹ãŠèã‹ã›ãã ã•ã„ï¼**
